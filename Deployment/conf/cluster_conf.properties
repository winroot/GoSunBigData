################################################################################
## Copyright:   HZGOSUN Tech. Co, BigData
## Filename:    cluster_conf.properties
## Description: 一键配置集群脚本的配置文件
## Version:     2.0
## Author:      zhangbaolin
## Created:     2018-6-21
################################################################################

#---------------------------------------------------------------------#
#                              使用说明                                #
#---------------------------------------------------------------------#

# 一键配置脚本从这个配置文件根据key关键字读取需要修改的配置，
# 例如根据关键字[ZOOKEEPER]读取[ZOOKEEPER=]后的内容，并将该内容配入相应的文件。

# 【格式】
# 键与值之间用[等号=]分割，例如ZOOKEEPER=172.18.18.106:2181
# 同一个键的值之间用[分号;]分割，例如172.18.18.106:2181;172.18.18.107:2181

# 【配置方法】
# 进行配置时，只需修改“key=”key等号之后的内容即可。
# 有多余的ip号等在后面追加，并注意用[分号;]分割。
# 注意：不能更改key！！

#---------------------------------------------------------------------#
#                              密码配置                                #
#---------------------------------------------------------------------#
#一般为默认，不建议修改。

# ssh登录到其他节点时的密码
SSH_Password=123456

MYSQL_Password=Hzgc@123


#---------------------------------------------------------------------#
#                              FTP配置                                 #
#---------------------------------------------------------------------#
# ftp服务器的IP
# e.x:172.18.18.115;172.18.18.116;172.18.18.117
FTPIP=

#---------------------------------------------------------------------#
#                              集群类型配置                             #
#---------------------------------------------------------------------#
#是否为本地模式集群
#no意为完全分布式集群，有多个节点，yes意为本地模式集群，只有一个节点。默认为no
#若为yes，则下方集群安装配置均不生效（目录配置除外），只在本节点上安装所需服务。
ISLOCAL=no

#是否为小型化集群
#no意为标准集群，yes意为小型化集群。默认为no。
ISMINICLUSTER=no


#---------------------------------------------------------------------#
#                              集群配置                                #
#---------------------------------------------------------------------#

#  集群所有节点IP，用于在所有节点之间实现xcall和xsync工具；配置ssh免密码登录；关闭防火墙；
#  安装基础工具expectRpm，mysqlRpm，dos2unix；安装jdk
#  e.x:172.18.18.115;172.18.18.116;172.18.18.117
Cluster_HostName=

#  需要配置分发算法库的节点：e.x:172.18.18.115;172.18.18.116;172.18.18.117
GsFaceLib_HostName=

#----------------------------HADOOP组件安装配置---------------------------#

# 【HDFS安装节点】
#  目前支持ha模式，需要配置两个节点作为主备节点；
#  除namenode之外的节点可以配置datanode，
#  如果需要在namenode上启动datanode，请在安装hadoop后执行hadoop-damenon.sh start datanode；
#  主备节点：e.x:172.18.18.115;172.18.18.116
Hadoop_NameNode=
#  数据存储节点：e.x:172.18.18.116;172.18.18.117
Hadoop_DataNode=

# 【yarn】
#  除ResourceManager之外的节点可以配置datanode;如果需要在namenode上启动datanode yarn-dameon.sh start nodemanager
#  资源管理和调度节点：e.x:172.18.18.115;172.18.18.116
Yarn_ResourceManager=
#  执行任务节点：e.x:172.18.18.116;172.18.18.117
Yarn_NodeManager=
#  Yarn 的NodeManager 的个数
Yarn_NumOfNodeManger=

#----------------------------HIVE组件安装配置---------------------------#
#  安装节点：e.x:172.18.18.115;172.18.18.116;172.18.18.117
Meta_ThriftServer=

#  安装了mysql的节点：e.x:172.18.18.115(这是集群安装包所在节点，mysqlInstall.sh在该节点执行)
Mysql_InstallNode=

#----------------------------HBASE组件安装配置---------------------------#
# HBase 支持高可用，这里配置的节点为HBase备节点，主节点默认是执行启动HBase命令的节点
#  配置HBase备节点(高可用节点)：e.x:172.18.18.116（非启动HBase节点）
HBase_Hmaster=
#  从节点：e.x:172.18.18.115;172.18.18.117
HBase_HRegionServer=

#----------------------------ES组件安装配置---------------------------#
#  安装节点：e.x:172.18.18.115;172.18.18.116;172.18.18.117
ES_InstallNode=

#----------------------------kibana组件安装配置---------------------------#
# kibana需安装到有ES的节点上
# 安装节点：e.x:172.18.18.115
Kibana_InstallNode=

#----------------------------Kafka组件安装配置---------------------------#
#  安装节点：e.x:172.18.18.115;172.18.18.116;172.18.18.117
Kafka_InstallNode=

#----------------------------RocketMQ组件安装配置---------------------------#
#  主节点：e.x:172.18.18.117（主节点只有一个节点）
RocketMQ_Namesrv=
#  从节点：e.x:172.18.18.115;172.18.18.116
RocketMQ_Broker=

#----------------------------ZOOKEEPER组件安装配置---------------------------#
#  安装节点：e.x:172.18.18.115;172.18.18.116;172.18.18.117
Zookeeper_InstallNode=

#----------------------------SPARK组件安装配置---------------------------#
#  主节点：e.x:172.18.18.115（主节点只有一个节点）
Spark_NameNode=
# 从节点：e.x:172.18.18.116;172.18.18.117
Spark_ServiceNode=

#----------------------------HAproxy组件安装配置---------------------------#
#  代理节点：e.x:172.18.18.116（代理节点只有一个节点）
HAproxy_AgencyNode=
#  服务节点：e.x:172.18.18.115;172.18.18.117
HAproxy_ServiceNode=

#----------------------------Scala组件安装配置---------------------------#
#  安装节点：e.x:172.18.18.115;172.18.18.116;172.18.18.117
Scala_InstallNode=

#---------------------------------------------------------------------#
#                              目录配置                                #
#---------------------------------------------------------------------#
#一般为默认，不建议修改。

## Source文件所在目录:(用于source 大数据环境变量)
Source_File=/opt/hzgc/env_bigdata.sh

## 一些系统额外需要的配置安装路径，比如expectRpm，mysqlRpm，dos2unix
System_SuportDir=/opt/hzgc/basic_suports

## 大数据相关的组件安装根目录
Install_HomeDir=/opt/hzgc/bigdata

## Source文件、集群服务启动和停止的文件目录:
Cluster_ServiceDir=/opt/hzgc/service

## 集群组件的日志文件目录（组建中已写死不能修改）:
Cluster_LOGSDir=/opt/hzgc/logs

## WebUI地址存放目录：
WebUI_Dir=/opt/hzgc
